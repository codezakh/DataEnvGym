# This file was autogenerated by uv via the following command:
#    uv pip compile requirements.in -o requirements.txt
-e .
    # via -r requirements.in
-e src/external/LLaMA-Factory
    # via -r requirements.in
accelerate==0.31.0
    # via
    #   llamafactory
    #   peft
    #   trl
aiofiles==23.2.1
    # via gradio
aiohappyeyeballs==2.4.0
    # via aiohttp
aiohttp==3.10.5
    # via
    #   datasets
    #   fsspec
    #   instructor
    #   vllm
aiosignal==1.3.1
    # via
    #   aiohttp
    #   ray
annotated-types==0.7.0
    # via pydantic
anyio==4.4.0
    # via
    #   gradio
    #   httpx
    #   openai
    #   sse-starlette
    #   starlette
    #   watchfiles
asttokens==2.4.1
    # via
    #   icecream
    #   stack-data
async-timeout==4.0.3
    # via aiohttp
attrs==24.2.0
    # via
    #   -r requirements.in
    #   aiohttp
    #   jsonschema
    #   referencing
certifi==2024.8.30
    # via
    #   httpcore
    #   httpx
    #   requests
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via
    #   -r requirements.in
    #   ray
    #   typer
    #   uvicorn
cloudpickle==3.0.0
    # via outlines
colorama==0.4.6
    # via icecream
contourpy==1.2.1
    # via matplotlib
cycler==0.12.1
    # via matplotlib
datasets==2.21.0
    # via
    #   -r requirements.in
    #   llamafactory
    #   outlines
    #   trl
decorator==5.1.1
    # via
    #   ipdb
    #   ipython
diffusers @ git+https://github.com/huggingface/diffusers.git@fbe29c62984c33c6cf9cf7ad120a992fe6d20854
    # via -r requirements.in
dill==0.3.8
    # via
    #   datasets
    #   multiprocess
diskcache==5.6.3
    # via outlines
distro==1.9.0
    # via openai
docstring-parser==0.16
    # via
    #   instructor
    #   tyro
einops==0.8.0
    # via llamafactory
exceptiongroup==1.2.2
    # via
    #   anyio
    #   ipython
executing==2.0.1
    # via
    #   icecream
    #   stack-data
fastapi==0.115.9
    # via
    #   gradio
    #   llamafactory
    #   vllm
ffmpy==0.3.2
    # via gradio
filelock==3.15.4
    # via
    #   datasets
    #   diffusers
    #   huggingface-hub
    #   ray
    #   torch
    #   transformers
    #   triton
    #   vllm
fire==0.6.0
    # via llamafactory
fonttools==4.52.1
    # via matplotlib
frozenlist==1.4.1
    # via
    #   aiohttp
    #   aiosignal
    #   ray
fsspec==2024.6.1
    # via
    #   datasets
    #   gradio-client
    #   huggingface-hub
    #   torch
gguf==0.9.1
    # via vllm
gitdb==4.0.11
    # via -r requirements.in
gradio==5.19.0
    # via llamafactory
gradio-client==1.7.2
    # via gradio
greenlet==3.1.1
    # via sqlalchemy
h11==0.14.0
    # via
    #   httpcore
    #   uvicorn
httpcore==1.0.5
    # via httpx
httptools==0.6.1
    # via uvicorn
httpx==0.27.2
    # via
    #   gradio
    #   gradio-client
    #   openai
    #   safehttpx
huggingface-hub==0.28.1
    # via
    #   -r requirements.in
    #   accelerate
    #   datasets
    #   diffusers
    #   gradio
    #   gradio-client
    #   peft
    #   tokenizers
    #   transformers
hydra-core @ git+https://github.com/facebookresearch/hydra.git@f4fe48442992defef7c2ddd0a6d014e3c371a073
    # via -r requirements.in
icecream==2.1.3
    # via -r requirements.in
idna==3.8
    # via
    #   anyio
    #   httpx
    #   requests
    #   yarl
importlib-metadata==8.4.0
    # via
    #   diffusers
    #   vllm
instructor==1.7.0
    # via -r requirements.in
interegular==0.3.3
    # via
    #   lm-format-enforcer
    #   outlines
ipdb==0.13.13
    # via -r requirements.in
ipython==8.24.0
    # via
    #   -r requirements.in
    #   ipdb
jedi==0.19.1
    # via ipython
jinja2==3.1.4
    # via
    #   -r requirements.in
    #   gradio
    #   instructor
    #   outlines
    #   torch
jiter==0.6.1
    # via
    #   instructor
    #   openai
joblib==1.4.2
    # via scikit-learn
jsonschema==4.23.0
    # via
    #   mistral-common
    #   outlines
    #   ray
jsonschema-specifications==2023.12.1
    # via jsonschema
kiwisolver==1.4.5
    # via matplotlib
lark==1.2.2
    # via outlines
llvmlite==0.43.0
    # via numba
lm-format-enforcer==0.10.6
    # via vllm
loguru==0.7.2
    # via -r requirements.in
markdown-it-py==3.0.0
    # via rich
markupsafe==2.1.5
    # via
    #   gradio
    #   jinja2
matplotlib==3.9.0
    # via
    #   llamafactory
    #   seaborn
matplotlib-inline==0.1.7
    # via ipython
mdurl==0.1.2
    # via markdown-it-py
mistral-common==1.3.4
    # via vllm
mpmath==1.3.0
    # via sympy
msgpack==1.0.8
    # via ray
msgspec==0.18.6
    # via vllm
multidict==6.0.5
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.16
    # via datasets
nest-asyncio==1.6.0
    # via outlines
networkx==3.3
    # via torch
numba==0.60.0
    # via outlines
numpy==1.26.4
    # via
    #   -r requirements.in
    #   accelerate
    #   contourpy
    #   datasets
    #   diffusers
    #   gguf
    #   gradio
    #   llamafactory
    #   matplotlib
    #   numba
    #   outlines
    #   pandas
    #   peft
    #   pyarrow
    #   scikit-learn
    #   scipy
    #   seaborn
    #   torchvision
    #   transformers
    #   trl
    #   vllm
    #   xformers
nvidia-cublas-cu12==12.1.3.1
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.1.105
    # via torch
nvidia-cuda-nvrtc-cu12==12.1.105
    # via torch
nvidia-cuda-runtime-cu12==12.1.105
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.0.2.54
    # via torch
nvidia-curand-cu12==10.3.2.106
    # via torch
nvidia-cusolver-cu12==11.4.5.107
    # via torch
nvidia-cusparse-cu12==12.1.0.106
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-ml-py==12.560.30
    # via vllm
nvidia-nccl-cu12==2.20.5
    # via torch
nvidia-nvjitlink-cu12==12.6.68
    # via
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
nvidia-nvtx-cu12==12.1.105
    # via torch
omegaconf @ git+https://github.com/omry/omegaconf@6f9656bf091f6cb1ebfe22c926e60e1c9d25ca02
    # via
    #   -r requirements.in
    #   hydra-core
openai==1.61.1
    # via
    #   -r requirements.in
    #   instructor
    #   vllm
orjson==3.10.3
    # via gradio
outlines==0.0.46
    # via vllm
packaging==24.1
    # via
    #   accelerate
    #   datasets
    #   gradio
    #   gradio-client
    #   huggingface-hub
    #   hydra-core
    #   llamafactory
    #   lm-format-enforcer
    #   matplotlib
    #   peft
    #   ray
    #   transformers
pandas==2.2.2
    # via
    #   -r requirements.in
    #   datasets
    #   gradio
    #   llamafactory
    #   seaborn
parso==0.8.4
    # via jedi
partial-json-parser==0.2.1.1.post4
    # via vllm
pebble==5.0.7
    # via -r requirements.in
peft==0.12.0
    # via
    #   -r requirements.in
    #   llamafactory
pexpect==4.9.0
    # via ipython
pillow==10.4.0
    # via
    #   -r requirements.in
    #   diffusers
    #   gradio
    #   matplotlib
    #   torchvision
    #   vllm
prometheus-client==0.20.0
    # via
    #   prometheus-fastapi-instrumentator
    #   vllm
prometheus-fastapi-instrumentator==7.0.0
    # via vllm
prompt-toolkit==3.0.43
    # via ipython
protobuf==5.28.0
    # via
    #   llamafactory
    #   ray
    #   vllm
psutil==6.0.0
    # via
    #   accelerate
    #   peft
    #   vllm
ptyprocess==0.7.0
    # via pexpect
pure-eval==0.2.2
    # via stack-data
py-cpuinfo==9.0.0
    # via vllm
pyairports==2.1.1
    # via outlines
pyarrow==17.0.0
    # via datasets
pycountry==24.6.1
    # via outlines
pydantic==2.10.6
    # via
    #   -r requirements.in
    #   fastapi
    #   gradio
    #   instructor
    #   llamafactory
    #   lm-format-enforcer
    #   mistral-common
    #   openai
    #   outlines
    #   vllm
pydantic-core==2.27.2
    # via
    #   instructor
    #   pydantic
pydub==0.25.1
    # via gradio
pyext==0.7
    # via -r requirements.in
pygments==2.18.0
    # via
    #   icecream
    #   ipython
    #   rich
pyparsing==3.1.2
    # via matplotlib
python-dateutil==2.9.0.post0
    # via
    #   matplotlib
    #   pandas
python-dotenv==1.0.1
    # via uvicorn
python-multipart==0.0.20
    # via gradio
python-ulid==2.7.0
    # via -r requirements.in
pytz==2024.1
    # via pandas
pyyaml==6.0.2
    # via
    #   accelerate
    #   datasets
    #   gradio
    #   huggingface-hub
    #   llamafactory
    #   lm-format-enforcer
    #   omegaconf
    #   peft
    #   ray
    #   transformers
    #   uvicorn
    #   vllm
pyzmq==26.2.0
    # via vllm
ray==2.35.0
    # via
    #   -r requirements.in
    #   vllm
referencing==0.35.1
    # via
    #   jsonschema
    #   jsonschema-specifications
    #   outlines
regex==2024.7.24
    # via
    #   diffusers
    #   tiktoken
    #   transformers
requests==2.32.3
    # via
    #   datasets
    #   diffusers
    #   huggingface-hub
    #   instructor
    #   outlines
    #   ray
    #   tiktoken
    #   transformers
    #   vllm
rich==13.7.1
    # via
    #   -r requirements.in
    #   instructor
    #   typer
    #   tyro
rpds-py==0.20.0
    # via
    #   jsonschema
    #   referencing
ruff==0.9.9
    # via gradio
safehttpx==0.1.6
    # via gradio
safetensors==0.4.4
    # via
    #   accelerate
    #   diffusers
    #   peft
    #   transformers
scikit-learn==1.5.1
    # via -r requirements.in
scipy==1.14.1
    # via
    #   llamafactory
    #   scikit-learn
seaborn==0.13.2
    # via -r requirements.in
semantic-version==2.10.0
    # via gradio
sentencepiece==0.2.0
    # via
    #   llamafactory
    #   mistral-common
    #   vllm
sh==2.0.6
    # via -r requirements.in
shellingham==1.5.4
    # via typer
shtab==1.7.1
    # via tyro
six==1.16.0
    # via
    #   asttokens
    #   fire
    #   python-dateutil
smmap==5.0.1
    # via gitdb
sniffio==1.3.1
    # via
    #   anyio
    #   httpx
    #   openai
sqlalchemy==2.0.36
    # via -r requirements.in
sse-starlette==2.1.3
    # via llamafactory
stack-data==0.6.3
    # via ipython
starlette==0.45.3
    # via
    #   fastapi
    #   gradio
    #   prometheus-fastapi-instrumentator
    #   sse-starlette
sympy==1.13.2
    # via
    #   -r requirements.in
    #   torch
tenacity==9.0.0
    # via
    #   -r requirements.in
    #   instructor
termcolor==2.4.0
    # via fire
threadpoolctl==3.5.0
    # via scikit-learn
tiktoken==0.7.0
    # via
    #   llamafactory
    #   mistral-common
    #   vllm
tokenizers==0.19.1
    # via
    #   transformers
    #   vllm
tomli==2.0.1
    # via ipdb
tomlkit==0.12.0
    # via gradio
torch==2.4.0
    # via
    #   accelerate
    #   peft
    #   torchvision
    #   trl
    #   vllm
    #   vllm-flash-attn
    #   xformers
torchvision==0.19.0
    # via vllm
tqdm==4.66.5
    # via
    #   -r requirements.in
    #   datasets
    #   gguf
    #   huggingface-hub
    #   openai
    #   outlines
    #   peft
    #   transformers
    #   vllm
traitlets==5.14.3
    # via
    #   ipython
    #   matplotlib-inline
transformers==4.44.2
    # via
    #   -r requirements.in
    #   llamafactory
    #   peft
    #   trl
    #   vllm
triton==3.0.0
    # via torch
trl @ git+https://github.com/huggingface/trl.git@ac7c8b128494dc98db3c795c728da3bf7abed981
    # via
    #   -r requirements.in
    #   llamafactory
typer==0.12.3
    # via
    #   gradio
    #   instructor
typing-extensions==4.12.2
    # via
    #   -r requirements.in
    #   anyio
    #   fastapi
    #   gradio
    #   gradio-client
    #   huggingface-hub
    #   ipython
    #   mistral-common
    #   openai
    #   outlines
    #   pydantic
    #   pydantic-core
    #   sqlalchemy
    #   torch
    #   typer
    #   tyro
    #   uvicorn
    #   vllm
tyro==0.8.5
    # via trl
tzdata==2024.1
    # via pandas
urllib3==2.2.2
    # via requests
uvicorn==0.30.6
    # via
    #   gradio
    #   llamafactory
    #   sse-starlette
    #   vllm
uvloop==0.20.0
    # via uvicorn
vllm==0.6.0
    # via -r requirements.in
vllm-flash-attn==2.6.1
    # via vllm
watchfiles==0.24.0
    # via uvicorn
wcwidth==0.2.13
    # via prompt-toolkit
websockets==13.0.1
    # via
    #   gradio-client
    #   uvicorn
xformers==0.0.27.post2
    # via vllm
xxhash==3.5.0
    # via datasets
yarl==1.9.11
    # via aiohttp
zipp==3.20.1
    # via importlib-metadata
